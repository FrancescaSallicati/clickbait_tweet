model,accuracy,f1_score,precision,recall,runtime
cnn_baseline,0.833818316491191,0.595492594977463,0.6968053044002411,0.5199010568922869,20.736634492874146
cnn_classWeights,0.8059361938521772,0.6273115220483639,0.5721964782205746,0.69417584888689,17.270848751068115
lstm_baseline,0.8399026506534046,0.6551173922954183,0.6642015253062168,0.6462783899257927,17.070773601531982
lstm_classWeights,0.8025501296227713,0.6473256473256472,0.5582722086389568,0.7701821452664718,16.89257788658142
gru_baseline,0.8452462832654357,0.6308216584627035,0.7189298043728424,0.5619518776703396,15.96357274055481
gru_classWeights,0.822707793238453,0.6614809576724923,0.6005135730007337,0.7362266696649427,15.741523742675781
gru_fastText_hardPreproc,0.8413840537537697,0.620217887002787,0.7101827676240209,0.5504834720035979,19.237488746643066
gru_fastText_hardPreproc_classWeights,0.8194804507698006,0.6481748814188493,0.5985526566368311,0.706768608050371,19.731279611587524
gru_fastText_softPreproc,0.8461457065763717,0.6518199233716475,0.6970550576184379,0.6120980436249157,25.66502332687378
gru_fastText_softPreproc_classWeights,0.8158298502724723,0.6625302956858943,0.5823108384458078,0.7683831796716888,25.987305879592896
bert_cased,0.8668640617564638,0.7118333714808882,0.7266355140186916,0.6976222521310005,446.22482204437256
bert_cased_classWeigths,0.8563950721725797,0.7153636554181513,0.6713217938630999,0.7655899506505159,508.9956941604614
bert_uncased,0.8690318828319146,0.7170113104078603,0.7306169965075671,0.7039030955585465,508.29084038734436
bert_uncased_classWeigths,0.8509490826415693,0.7199761597298103,0.6461044749509717,0.8129205921938089,385.98862648010254
bertweet,0.8707767144292285,0.7385537013264869,0.7059304703476482,0.7743382682817407,514.0483787059784
bertweet_classWeigths,0.8517421879130757,0.7252058016464131,0.6439262095370692,0.8299685957828623,515.9181363582611
