{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64289f50-c8ac-4e07-b036-b168d7b0cdcc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e251ada-d4ab-403b-8917-716ed0a83f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.preprocessing import clean_tweet_for_transformers\n",
    "from src.utils import read_data\n",
    "from src.utils import evaluate_model, compute_metrics\n",
    "from src.utils import set_seed\n",
    "#set_seed(20042022)\n",
    "\n",
    "from transformers import TFAutoModel,AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a039a7d-93f6-475f-989a-664247f1203e",
   "metadata": {},
   "source": [
    "## Load results.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34633d3b-a1e0-45ee-acdb-0fa5555a21fe",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "The metrics used to assess this task are some of the most commonly used to evaluate binary classification problems: <br />\n",
    "- **Accuracy**: Accuracy measures the ratio of correctly predicted observation to the total observations. <br />\n",
    "-**F1 score**:F1 Score is the weighted average of Precision and Recall. It is usually more useful than accuracy, especially with unbalanced class distribution, like in our case. <br />\n",
    "-**Precision**: Precision is the fraction of positive instances among all retrieved instances <br />\n",
    "-**Recall**: Recall is defined as the fraction of retrieved instances among all relevant instances from the positive class. <br />\n",
    "\n",
    "It is worth remembering that our dataset is unbalanced, therefore is it advisable to favour f1 score rather than acuracy when selecting the best model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842538a7-f872-426c-9c8c-1e1a4a06be20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../trained_models/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36aa68-142e-45e7-ac78-8ae24e16e795",
   "metadata": {},
   "source": [
    "The following tables shows the metrics obtained for the tested model architectures and the model runtime (trained with GPU).The training time grows significatively when fine-tuning transformers architecture to suit this tasks, but the models provide better results for this problem.  <br />\n",
    "\n",
    "For the neural networks models, three different architectures were trained, exploring simple CNN, LSTM and GRU models. These models have been trained both normally and with class weights to smoothing the unbalanced data. Among these three models, the best resulting model, namely the GRU architecture, is then used to explore transfer learning with fastText pretrained embeddings too, applying 2 different preprocessing functions. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62dc7e82-0c94-4b68-8dde-469c96bd21f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_baseline</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>0.595493</td>\n",
       "      <td>0.696805</td>\n",
       "      <td>0.519901</td>\n",
       "      <td>20.736634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_classWeights</td>\n",
       "      <td>0.805936</td>\n",
       "      <td>0.627312</td>\n",
       "      <td>0.572196</td>\n",
       "      <td>0.694176</td>\n",
       "      <td>17.270849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm_baseline</td>\n",
       "      <td>0.839903</td>\n",
       "      <td>0.655117</td>\n",
       "      <td>0.664202</td>\n",
       "      <td>0.646278</td>\n",
       "      <td>17.070774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lstm_classWeights</td>\n",
       "      <td>0.802550</td>\n",
       "      <td>0.647326</td>\n",
       "      <td>0.558272</td>\n",
       "      <td>0.770182</td>\n",
       "      <td>16.892578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gru_baseline</td>\n",
       "      <td>0.845246</td>\n",
       "      <td>0.630822</td>\n",
       "      <td>0.718930</td>\n",
       "      <td>0.561952</td>\n",
       "      <td>15.963573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gru_classWeights</td>\n",
       "      <td>0.822708</td>\n",
       "      <td>0.661481</td>\n",
       "      <td>0.600514</td>\n",
       "      <td>0.736227</td>\n",
       "      <td>15.741524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gru_fastText_hardPreproc</td>\n",
       "      <td>0.841384</td>\n",
       "      <td>0.620218</td>\n",
       "      <td>0.710183</td>\n",
       "      <td>0.550483</td>\n",
       "      <td>19.237489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gru_fastText_hardPreproc_classWeights</td>\n",
       "      <td>0.819480</td>\n",
       "      <td>0.648175</td>\n",
       "      <td>0.598553</td>\n",
       "      <td>0.706769</td>\n",
       "      <td>19.731280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gru_fastText_softPreproc</td>\n",
       "      <td>0.846146</td>\n",
       "      <td>0.651820</td>\n",
       "      <td>0.697055</td>\n",
       "      <td>0.612098</td>\n",
       "      <td>25.665023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gru_fastText_softPreproc_classWeights</td>\n",
       "      <td>0.815830</td>\n",
       "      <td>0.662530</td>\n",
       "      <td>0.582311</td>\n",
       "      <td>0.768383</td>\n",
       "      <td>25.987306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model  accuracy  f1_score  precision  \\\n",
       "0                           cnn_baseline  0.833818  0.595493   0.696805   \n",
       "1                       cnn_classWeights  0.805936  0.627312   0.572196   \n",
       "2                          lstm_baseline  0.839903  0.655117   0.664202   \n",
       "3                      lstm_classWeights  0.802550  0.647326   0.558272   \n",
       "4                           gru_baseline  0.845246  0.630822   0.718930   \n",
       "5                       gru_classWeights  0.822708  0.661481   0.600514   \n",
       "6               gru_fastText_hardPreproc  0.841384  0.620218   0.710183   \n",
       "7  gru_fastText_hardPreproc_classWeights  0.819480  0.648175   0.598553   \n",
       "8               gru_fastText_softPreproc  0.846146  0.651820   0.697055   \n",
       "9  gru_fastText_softPreproc_classWeights  0.815830  0.662530   0.582311   \n",
       "\n",
       "     recall    runtime  \n",
       "0  0.519901  20.736634  \n",
       "1  0.694176  17.270849  \n",
       "2  0.646278  17.070774  \n",
       "3  0.770182  16.892578  \n",
       "4  0.561952  15.963573  \n",
       "5  0.736227  15.741524  \n",
       "6  0.550483  19.237489  \n",
       "7  0.706769  19.731280  \n",
       "8  0.612098  25.665023  \n",
       "9  0.768383  25.987306  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_networks = df.iloc[:10,:]\n",
    "df_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b18548e2-3cfc-4239-b464-23f11b91ecef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert_cased</td>\n",
       "      <td>0.866864</td>\n",
       "      <td>0.711833</td>\n",
       "      <td>0.726636</td>\n",
       "      <td>0.697622</td>\n",
       "      <td>446.224822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert_cased_classWeigths</td>\n",
       "      <td>0.856395</td>\n",
       "      <td>0.715364</td>\n",
       "      <td>0.671322</td>\n",
       "      <td>0.765590</td>\n",
       "      <td>508.995694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert_uncased</td>\n",
       "      <td>0.869032</td>\n",
       "      <td>0.717011</td>\n",
       "      <td>0.730617</td>\n",
       "      <td>0.703903</td>\n",
       "      <td>508.290840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert_uncased_classWeigths</td>\n",
       "      <td>0.850949</td>\n",
       "      <td>0.719976</td>\n",
       "      <td>0.646104</td>\n",
       "      <td>0.812921</td>\n",
       "      <td>385.988626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bertweet</td>\n",
       "      <td>0.870777</td>\n",
       "      <td>0.738554</td>\n",
       "      <td>0.705930</td>\n",
       "      <td>0.774338</td>\n",
       "      <td>514.048379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bertweet_classWeigths</td>\n",
       "      <td>0.851742</td>\n",
       "      <td>0.725206</td>\n",
       "      <td>0.643926</td>\n",
       "      <td>0.829969</td>\n",
       "      <td>515.918136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  accuracy  f1_score  precision    recall  \\\n",
       "10                 bert_cased  0.866864  0.711833   0.726636  0.697622   \n",
       "11    bert_cased_classWeigths  0.856395  0.715364   0.671322  0.765590   \n",
       "12               bert_uncased  0.869032  0.717011   0.730617  0.703903   \n",
       "13  bert_uncased_classWeigths  0.850949  0.719976   0.646104  0.812921   \n",
       "14                   bertweet  0.870777  0.738554   0.705930  0.774338   \n",
       "15      bertweet_classWeigths  0.851742  0.725206   0.643926  0.829969   \n",
       "\n",
       "       runtime  \n",
       "10  446.224822  \n",
       "11  508.995694  \n",
       "12  508.290840  \n",
       "13  385.988626  \n",
       "14  514.048379  \n",
       "15  515.918136  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformers = df.iloc[10:,:]\n",
    "df_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4fe76-81da-47be-8139-0077336349e5",
   "metadata": {},
   "source": [
    "In the second table the results for the transformers model are displayed. BERT fine-tuning is explored both from its cased and uncased version; additionally the BERTweet transformers is also tested. All experiments come both in normal and class weigtht training and show that the introduction of class weights is useful to better detect 'clickbait' tweets, at the cost of a reasonable loss in the evaluation metrics. <br />\n",
    "\n",
    "Two different preprocessing functions were used to better clean the text of tweets, suiting the needs of the different architectures (deeper for simple neural networks, softer for transformers). This choice has been taken since for transformers the preprocessing seems to impact less on the performances of the models, due to different motivations. For instance, BERT models uses BPE in the encoding and it can handle the input sequences even though lemmatization or stemming are not applied. <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825b889-a04b-4214-b712-10582be10a08",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e13171-a35b-49c6-88df-c52d7011a264",
   "metadata": {},
   "source": [
    "From the results obtained with these experiments, we can observe that the trasnformer models fine-tuned for this task performs better than the CNNs, LSTMs and GRUs networks that have been tested. Most of the times, we can see that with the class weight option helps the models to better capture the 'true clickbait' tweets, at the cost of negatively classifying as clickbaits some of the 'no-clickbait' tweets. This results in the models being slightly more balanced in their predictions, having lower accuracy, but higher f1 score.\n",
    "\n",
    "In particular, the BERTweet model, which is a variation of the ROBERTa model designed to work with tweets data performs best among all models. Its class weighted version does not seems to provide an improvement over the baseline BERTweets, showing lower f1-score and more unbalanced precision and recall metrics. Therefore we consider the tweetbert baseline the best model among the tested architectures.\n",
    "\n",
    "Next, we will center on this model and explore some of the bad and good predictions that are generated. Additionally by analysing the ROC curve of classifier, we search for the optimal threshold and compare the difference among the predictions obtained with the standard threshold of 0.5 and the threshold obtained with this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d31cbe-ac7d-45dc-91e5-21a0142834ea",
   "metadata": {},
   "source": [
    "### Load Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e07eec48-eed8-4bd1-a90d-abc1dc9cdae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "filename = '../data/webis_test.csv'\n",
    "test_df = read_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb58608-9e00-452b-8760-eeaeebd2e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../trained_models/BERTWEET/bertweet\")\n",
    "model = tf.keras.models.load_model(\"../trained_models/BERTWEET/bertweet\")\n",
    "\n",
    "max_seq_len = 40\n",
    "#Apply same preprocessing and tokenizer to test dataset tweets\n",
    "test_df['cleanedText'] = test_df.postText.apply(lambda x: clean_tweet_for_transformers(x))\n",
    "test_df  = test_df.loc[test_df.cleanedText != '']\n",
    "\n",
    "test_x = tokenizer(\n",
    "    text=test_df['cleanedText'].astype(str).to_list(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_seq_len,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c1785-2463-4994-9686-a07bed5f2a60",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db4ad59-9fd8-4a53-9739-2c841a25f494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/592 [==============================] - 33s 56ms/step - loss: 0.2926 - accuracy: 0.8708\n",
      "Test loss: 0.2926306426525116\n",
      "Test accuracy 0.8707767128944397\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.93      0.90      0.91     14455\n",
      "   clickbait       0.71      0.77      0.74      4458\n",
      "\n",
      "    accuracy                           0.87     18913\n",
      "   macro avg       0.82      0.84      0.83     18913\n",
      "weighted avg       0.88      0.87      0.87     18913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = test_df.label.values\n",
    "##Evaluate CNN model\n",
    "predictions = evaluate_model(model, {'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']}, y_test, threshold = 0.5)\n",
    "##Get Classification report\n",
    "classes = ['no-clickbait', 'clickbait']\n",
    "print(\"\\nClassification report : \\n\", classification_report(y_test, predictions, zero_division = 0, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97e5396-cc48-4dcb-a428-dbc1dd53f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f210c408f90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Get Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8357c-6807-4d73-852e-7dc84d4972a2",
   "metadata": {},
   "source": [
    "From the confusion matrix we can deduce that the classifier works quite well for both classes, although its ability to capture 'clickbait' tweets is lower when compared to the capacity of capturing 'no-clickbait' tweets. \n",
    "\n",
    "Next the precision and recall score are quite balanced, meaning that the classifier is considering both the correct classification for both classes and for clickbait tweets as well.\n",
    "\n",
    "Both accuracy and f1 score are the best among all the tested architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a73002-b943-4634-b70d-094a9fec5d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8707767144292285\n",
      "F1 Score:  0.7385537013264869\n",
      "Precision Score:  0.7059304703476482\n",
      "Recall Score:  0.7743382682817407\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, precision, recall = compute_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc331e8c-c461-46aa-99c5-eeb8e4f51f8a",
   "metadata": {},
   "source": [
    "### Examples fo bad predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c75fdf00-efc2-4683-929a-bdc3a01e82d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text:  This 71-year-old grandpa rocks Supreme better than you.\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Meet The 71-Year-Old Grandpa Who Rocks Supreme Harder Than You\n",
      "\n",
      "\n",
      "Tweet text:  How will each Power 5 conference team finish? \n",
      "\n",
      "Full projections:\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  College Football 2017: Projecting the Record of Every Power 5 Conference Team\n",
      "\n",
      "\n",
      "Tweet text:  If youâ€™ve ever wondered what your dog is thinking â€¦ this smart collar will help\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  If youâ€™ve ever wondered what your dog is thinking â€¦ this smart collar will help\n",
      "\n",
      "\n",
      "Tweet text:  â€œCome with me, your wife is here.â€ This moment seemed impossible to Mohammed Alqalos just 6 weeks ago.\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Caught Up in Travel Ban, a Family Reunites \n",
      "\n",
      "\n",
      "Tweet text:  Riding the wave: Meet the surfer who helped 7 million people get clean water\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Meet the Former Pro Surfer Who Has Helped 7 Million People Get Clean Water\n",
      "\n",
      "\n",
      "Tweet text:  North Korea's history of covert operations and secret killings\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  North Korea's history of covert operations and secret killings\n",
      "\n",
      "\n",
      "Tweet text:  The #students were left fighting for their lives following an #experiment that went haywire in March 2015\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  British University Fined Â£400,000 For Almost Killing Students During 'Coffee Experiment'\n",
      "\n",
      "\n",
      "Tweet text:  This wild geode hair trend is going to be all over Instagram soon\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  This Wild Geode Hair Trend Is Going To Be All Over Instagram Soon\n",
      "\n",
      "\n",
      "Tweet text:  The reach for yield is alive and well\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Bond Buying Surges, Tightening U.S. Corporate Spreads\n",
      "\n",
      "\n",
      "Tweet text:  One bettor is 13 minutes away from winning $1 million on his $1.1 million Falcons bet:\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  $1.1 million wager placed on underdog Falcons\n",
      "\n",
      "\n",
      "Tweet text:  Everything you need to know about the anarchist tactics behind that viral nazi-punch\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Everything You Need to Know About the Anarchist Tactics Behind That Viral Nazi-Punch\n",
      "\n",
      "\n",
      "Tweet text:  This Missy Elliott lyric from 2002 has the internet in shambles\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  This Missy Elliott Lyric From 2002 Shakes The Internet\n",
      "\n",
      "\n",
      "Tweet text:  Here's how to improve your upward-facing dog in yoga class  via @NBCNewsBETTER\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Do It Better: Improve Your Upward-Facing Dog in Yoga\n",
      "\n",
      "\n",
      "Tweet text:  A giant Donald Trump rooster is the new mascot of a mall in China\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Trump rooster statue erected in China\n",
      "\n",
      "\n",
      "Tweet text:  Trump administration hits small farmers with more bad news âž¡ï¸  by @robojojo\n",
      "Original label:  clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Trump Administration Hits Small Farmers With More Bad News\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = test_df.label.values\n",
    "raw_predictions = model.predict({'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']},)\n",
    "predictions_standard = np.where(raw_predictions > 0.5, 1, 0)\n",
    "\n",
    "indexes = []\n",
    "for index, (p1, y) in enumerate(zip(predictions_standard, y_test)):\n",
    "    if p1 != y:\n",
    "        #print(p1, y)\n",
    "        indexes.append(index)\n",
    "        \n",
    "test_df['predictedClass'] = [x for x in predictions_standard]\n",
    "wrong_predictions = test_df.iloc[indexes].sample(n=15)\n",
    "\n",
    "for i, obs in enumerate(wrong_predictions.iterrows()):\n",
    "    print('Tweet text: ',obs[1].postText)\n",
    "    print('Original label: ', obs[1].truthClass)\n",
    "    print('Predicted label: ', obs[1].predictedClass)\n",
    "    print('\\tRelated article: ',obs[1].targetTitle)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ae7c6-c955-4309-9cf7-6ccaf7c9f925",
   "metadata": {},
   "source": [
    "### Examples fo good predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a830d1-9386-4396-8920-3a9549e989c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text:  You can now order Plan B on Seamless\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  You Can Now Order Plan B On Seamless\n",
      "\n",
      "\n",
      "Tweet text:  Opinion: Stop obsessing over \"secrets\" about Trump and Russia. What we already know is bad enough.\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Stop obsessing over â€˜secretsâ€™ about Trump and Russia. What we already know is bad enough.\n",
      "\n",
      "\n",
      "Tweet text:  A Danish doctors association wants to end circumcision for boys, saying men should make the decision as adults\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Danish Doctorsâ€™ Group Wants to End Circumcision for Boys \n",
      "\n",
      "\n",
      "Tweet text:  Starbucks pledges to hire 10,000 refugees\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Starbucks pledges to hire 10,000 refugees\n",
      "\n",
      "\n",
      "Tweet text:  Fury over India flag doormats for sale on Amazon\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Fury over India flag doormats for sale on Amazon\n",
      "\n",
      "\n",
      "Tweet text:  You don't say.\n",
      "Original label:  clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Suicide Terrorism Across the Globe Hits Record High in 2016\n",
      "\n",
      "\n",
      "Tweet text:  Royal Mail union warns of industrial action over pension scheme closure\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Royal Mail union warns of industrial action over pension scheme closure\n",
      "\n",
      "\n",
      "Tweet text:  Hereâ€™s a complete guide for rewatching Twin Peaks, before it returns May 21\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Your Complete Guide to Rewatching â€˜Twin Peaksâ€™ - NYT Watching Search\n",
      "\n",
      "\n",
      "Tweet text:  Young Thug is being sued by a limo service:\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Young Thug Is Being Sued By A Limo Service\n",
      "\n",
      "\n",
      "Tweet text:  Living under flightpath roar 'may cause diabetes'\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Living under flightpath roar 'may cause diabetes': Scientists say residents who are exposed to daily aircraft noise are 86 per cent more likely to have the type 2 condition Â \n",
      "\n",
      "\n",
      "Tweet text:  George Orwellâ€™s \"1984\" back on bestseller list following \"alternative facts\"\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Sales of Orwellâ€™s Dystopian Classic â€˜1984â€™ Soar After Trump Claims, â€˜Alternative Factsâ€™\n",
      "\n",
      "\n",
      "Tweet text:  People are ticked that Rory McIlroy played golf with Donald Trump\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  People Are Ticked That Rory McIlroy Played Golf With Donald Trump\n",
      "\n",
      "\n",
      "Tweet text:  Why the EQT is going to be the Adidas sneaker of 2017:\n",
      "Original label:  clickbait\n",
      "Predicted label:  [1]\n",
      "\tRelated article:  Why the EQT Is Going to Be the Adidas Sneaker of 2017\n",
      "\n",
      "\n",
      "Tweet text:  An Abortion Is Not Out Of The Question For â€œGilmore Girlsâ€\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Amy Sherman-Palladino And Daniel Palladino Are Standing By The Final Four Words In â€œGilmoreÂ Girlsâ€\n",
      "\n",
      "\n",
      "Tweet text:  Wanna know how your team does? We got you.\n",
      "\n",
      "Our NFL FB Live Draft Show kicks off nowðŸŽ¥:\n",
      "Original label:  no-clickbait\n",
      "Predicted label:  [0]\n",
      "\tRelated article:  Facebook Live: 2017 NFL Draft Round 1 Live Grades and Reaction\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = test_df.label.values\n",
    "predictions_standard = np.where(raw_predictions > 0.5, 1, 0)\n",
    "\n",
    "indexes = []\n",
    "for index, (p1, y) in enumerate(zip(predictions_standard, y_test)):\n",
    "    if p1 == y:\n",
    "        #print(p1, y)\n",
    "        indexes.append(index)\n",
    "        \n",
    "test_df['predictedClass'] = [x for x in predictions_standard]\n",
    "wrong_predictions = test_df.iloc[indexes].sample(n=15)\n",
    "\n",
    "for i, obs in enumerate(wrong_predictions.iterrows()):\n",
    "    print('Tweet text: ',obs[1].postText)\n",
    "    print('Original label: ', obs[1].truthClass)\n",
    "    print('Predicted label: ', obs[1].predictedClass)\n",
    "    print('\\tRelated article: ',obs[1].targetTitle)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75413a5c-97c4-4260-a839-3bf86cfdae92",
   "metadata": {},
   "source": [
    "# ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031932f5-cd2a-4d77-8f4c-0425a057b5ed",
   "metadata": {},
   "source": [
    "This sections analyses the ROC curve in order to see if a better threshold for the model predictions can be found and how models predictions changes consequently. \n",
    "The ROC curve consists in a graph that shows the performances of the classifier across several threshold values. This can provide a better understanding of how the model can be tuned, depending on how we want to favour actual clickbait detection rather than no-clickbait correct classification.\n",
    "\n",
    "For that, we have to import the ground truth labels and the predictions first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d11b5191-f2e7-476b-8649-d72a5f282388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.        , 0.        , 0.        , ..., 0.98858526, 0.98872363,\n",
      "       1.        ]), array([0.00000000e+00, 2.24315837e-04, 6.72947510e-04, ...,\n",
      "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00]), array([1.979873  , 0.97987294, 0.97976905, ..., 0.0045189 , 0.0045145 ,\n",
      "       0.00303396], dtype=float32))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold=0.289161\n"
     ]
    }
   ],
   "source": [
    "#raw_predictions = model.predict({'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']})\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test, raw_predictions)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "print(roc_curve(y_test, raw_predictions))\n",
    "plt.figure()\n",
    "plt.plot(fpr[1], tpr[1])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "# calculate roc curves\n",
    "fpr, tpr, thresholds = roc_curve(y_test, raw_predictions)\n",
    "# get the best threshold\n",
    "diff = tpr - fpr\n",
    "indexes = np.argmax(diff)\n",
    "best_thresh = thresholds[indexes]\n",
    "print('Best Threshold=%f' % (best_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14d139b-bd2a-446f-8da5-20a4bedca75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8374\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(y_test, predictions)\n",
    "print(f\"ROC AUC: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b7eeb8-0031-4b59-92cd-b9e4f423b9fe",
   "metadata": {},
   "source": [
    "The ROC helps is a plot of the False Positive Rate (x-axis) versus the True Positive Rate (y-axis) for several threshold values (between (0,1)) and it helps to analyse how the efficiency of Binary Classifier.\n",
    "The best threshold depends on the objective of the model application and it is important to establish if it is more important to have all positives classified as positive (in this case clickait tweets), even if it means misclassifying some non clickbait tweets as clickbaits. <br />\n",
    "\n",
    "In this context, the ROC curve its quite good since it has a good balance between TPR and FPR, also known and sensitivity and specificity. The greater the area the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "686065de-2df2-48f0-9479-b741375c582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "no-clickbait       0.96      0.83      0.89     14455\n",
      "   clickbait       0.62      0.87      0.72      4458\n",
      "\n",
      "    accuracy                           0.84     18913\n",
      "   macro avg       0.79      0.85      0.81     18913\n",
      "weighted avg       0.88      0.84      0.85     18913\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions =np.where(raw_predictions > best_thresh, 1, 0)\n",
    "print(\"\\nClassification report : \\n\", classification_report(y_test, predictions, zero_division = 0, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31caea96-40ac-417b-9acd-e8d4573188fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f20d45c47d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Get Confusion Matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "540fe8e3-d18d-4bd9-b6f8-071a669b6075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8421720509702321\n",
      "F1 Score:  0.7231240144699007\n",
      "Precision Score:  0.6164795192155622\n",
      "Recall Score:  0.8743831314490803\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, precision, recall = compute_metrics(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31bbb62-b64d-4620-b414-f8ee127a8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8533\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(y_test, predictions)\n",
    "print(f\"ROC AUC: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a28b33-81b5-428a-9fc0-d75d0be57929",
   "metadata": {},
   "source": [
    "By applying the new threshold the model do detect more clickbait tweets, but the general performances drop thus meaning that more no-clickbai\n",
    "\n",
    "In the following part we will explore how predictions changes when adopting the new threshold suggest by the minimizationg of the difference between True Positive Rate and False Positive Rate. <br />\n",
    "More precisely, some random examples are selected from: <br />\n",
    "* tweets that are classified as 'clickbait' and are indeed 'clickbait' <br />\n",
    "* tweets that are misclassified as 'clickbait' being 'no-clickbait' <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4943f7d-0e85-41bc-acfb-fcb275ced71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_threshold =np.where(raw_predictions > best_thresh, 1, 0)\n",
    "predictions_standard = np.where(raw_predictions > 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c722f-eea9-4375-b004-6c5030697a2f",
   "metadata": {},
   "source": [
    "### Clickbait detected by new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84234c1b-ff29-47e1-a7f9-9fb59335b699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text:  Remembering the moments that turned Charlie Murphy into a comedy legend\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  The Moments That Turned Charlie Murphy Into a Comedy Legend\n",
      "\n",
      "\n",
      "Tweet text:  Trump's tech policy remains a mystery\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  President Trump's tech policy is a mystery\n",
      "\n",
      "\n",
      "Tweet text:  Lab notes: throw your hands in the air like you just don't care\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Lab notes: throw your hands in the air like you just don't care\n",
      "\n",
      "\n",
      "Tweet text:  Puff, puff, pass: @WizKhalifa's highest lyrics\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Puff, Puff, Pass: Wiz Khalifa's Highest Lyrics\n",
      "\n",
      "\n",
      "Tweet text:  The best employer in Canada is an institution older than the country itself. See the list:\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Canada's Best Employers 2017\n",
      "\n",
      "\n",
      "Tweet text:  Spoiler alert: Kawhi Leonard is his MVP.\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  NBA awards, Part 1: MVP, ROY, COY, DPOY, Sixth Man, MIP\n",
      "\n",
      "\n",
      "Tweet text:  The Fast &amp; Furious 8 trailer is absolutely bananas\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Fast and Furious 8 trailer: The Fate of the Furious looks totally bananas\n",
      "\n",
      "\n",
      "Tweet text:  Even Donald Trump can't save Twitter--Ahead of the Tape\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Even Donald Trump Canâ€™t Save Twitter \n",
      "\n",
      "\n",
      "Tweet text:  PewDiePie isnâ€™t a monster; heâ€™s someone you know\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  The Downfall Of YouTubeâ€™s Biggest Star Is A Symptom Of A BiggerÂ Illness\n",
      "\n",
      "\n",
      "Tweet text:  JPMorgan ChaseVoice: Leadership lessons from the CEO of JPMorgan Chase\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  JPMorgan ChaseVoice: Leadership Lessons From The CEO Of JPMorgan Chase\n",
      "\n",
      "\n",
      "Tweet text:  Someone just won the $435 million Powerball lottery\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Winning Powerball Ticket Worth $435 Million Sold In Indiana\n",
      "\n",
      "\n",
      "Tweet text:  Last year we envisaged President Trump and Brexit.\n",
      "\n",
      "Now here's a pessimist's guide to 2017:\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  The Pessimistâ€™s Guide to 2017\n",
      "\n",
      "\n",
      "Tweet text:  The person running Sweden's Twitter account is factchecking Trump and it's not pretty\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Swedenâ€™s official Twitter account debunks Donald Trump claims line by line\n",
      "\n",
      "\n",
      "Tweet text:  The world needs more fathers like them ðŸ˜‡ðŸ™Œ\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  9 Dads Who Are Literally Superhumans, The Sort That The World Really Needs\n",
      "\n",
      "\n",
      "Tweet text:  Not one movie rooted in real life was among 2016's top 10 box office performers\n",
      "Original label:  clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Reality? No, Thanks. Moviegoers Sought Escape in 2016. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for index, (p1, p2, y) in enumerate(zip(predictions_standard,predictions_threshold, y_test)):\n",
    "    if p1 != p2 and y == 1.0:\n",
    "        #print(index, p1, p2, y)\n",
    "        indexes.append(index)\n",
    "\n",
    "test_df['predictedClass'] = [x for x in predictions_standard]\n",
    "test_df['predictedClass_threshold'] = [x for x in predictions_threshold]\n",
    "clickait_detected_by_threshold = test_df.iloc[indexes].sample(n=15)\n",
    "\n",
    "for i, obs in enumerate(clickait_detected_by_threshold.iterrows()):\n",
    "    print('Tweet text: ',obs[1].postText)\n",
    "    print('Original label: ', obs[1].truthClass)\n",
    "    print('Predicted label - 0.5: ', obs[1].predictedClass)\n",
    "    print('Predicted label - '+str(best_thresh)[:4]+': ', obs[1].predictedClass_threshold)\n",
    "    print('\\tRelated article: ',obs[1].targetTitle)\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e4ab6-0b30-451f-a2ae-3e9dbb57380a",
   "metadata": {},
   "source": [
    "### No-Clickbait misclassified by new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3a55a75-0993-48b2-857d-5dc7bbd7d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text:  New year, new architecture: 2017's most anticipated building openings\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  New year, new buildings: 2017's most anticipated openings\n",
      "\n",
      "\n",
      "Tweet text:  High school kid becomes viral sensation after refusing to run from hail storm\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  High school kid becomes viral sensation after refusing to run from hail storm\n",
      "\n",
      "\n",
      "Tweet text:  The moment Russian model Viktoria Odintsova risks her life in daredevil Dubai photoshoot\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  The moment Russian model Viki Odintcova risks her life in daredevil Dubai photoshoot\n",
      "\n",
      "\n",
      "Tweet text:  Appease or oppose? How the world's nations are reacting to Trump\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Appease or oppose? How the world's nations are reacting to Trump\n",
      "\n",
      "\n",
      "Tweet text:  Controversial study claims monogamy may NOT be the best approach for human relationships\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Controversial study claims monogamy may NOT be the best approach for human relationships and is based on 'flawed science'\n",
      "\n",
      "\n",
      "Tweet text:  Snap has few challenges to overcome. The biggest: its home base\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Venice Is The Most Surprising Reason To Skip Snap's IPO\n",
      "\n",
      "\n",
      "Tweet text:  How Snapchat's first investor found Snapchat when it had less than 100,000 users\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  How Snapchat's first investor found Snapchat when it had less than 100,000 users\n",
      "\n",
      "\n",
      "Tweet text:  Fears around gender-neutral toilets are all in the mind | Paris Lees\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Fears around gender-neutral toilets are all in the mind\n",
      "\n",
      "\n",
      "Tweet text:  How much credit does Donald Trump deserve for Dow rally?\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  How much credit does Donald Trump deserve for Dow rally?\n",
      "\n",
      "\n",
      "Tweet text:  Absolutely phenomenal. Scientists turn spinach leaf into working heart tissue\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Scientists turn spinach leaf into working heart tissue\n",
      "\n",
      "\n",
      "Tweet text:  Review: Hey, hey, itâ€™s the Monkees!\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Hey, hey, itâ€™s the Monkees!\n",
      "\n",
      "\n",
      "Tweet text:  Our 2017 Tax Guide is here:\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  The Forbes 2017 Tax Guide\n",
      "\n",
      "\n",
      "Tweet text:  How can Peru prevent more devastating floods and landslides? â€“Â via @GuardianGDP\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  How can Peru prepare to withstand more devastating floods and landslides?\n",
      "\n",
      "\n",
      "Tweet text:  Woman jailed for playing Ed Sheeran song on repeat at top volume\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Woman jailed for playing Ed Sheeran song 'Shape of You' on repeat at top volume\n",
      "\n",
      "\n",
      "Tweet text:  The first pregnant British man announces he is with child\n",
      "Original label:  no-clickbait\n",
      "Predicted label - 0.5:  [0]\n",
      "Predicted label - 0.28:  [1]\n",
      "\tRelated article:  Meet the first British man to get pregnant The list\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexes = []\n",
    "for index, (p1, p2, y) in enumerate(zip(predictions_standard,predictions_threshold, y_test)):\n",
    "    if p1 != p2 and y == 0.0:\n",
    "        #print(index, p1, p2, y)\n",
    "        indexes.append(index)\n",
    "    \n",
    "clickait_detected_by_threshold = test_df.iloc[indexes].sample(n=15)\n",
    "for i, obs in enumerate(clickait_detected_by_threshold.iterrows()):\n",
    "    print('Tweet text: ',obs[1].postText)\n",
    "    print('Original label: ', obs[1].truthClass)\n",
    "    print('Predicted label - 0.5: ', obs[1].predictedClass)\n",
    "    print('Predicted label - '+str(best_thresh)[:4]+': ', obs[1].predictedClass_threshold)\n",
    "    print('\\tRelated article: ',obs[1].targetTitle)\n",
    "    print('\\n')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-clickbait_detection]",
   "language": "python",
   "name": "conda-env-.conda-clickbait_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
